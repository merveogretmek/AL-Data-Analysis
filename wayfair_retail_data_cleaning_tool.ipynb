{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ce6cf1",
   "metadata": {},
   "source": [
    "# Wayfair Data Cleaning Automation Tool\n",
    "\n",
    "## Overview\n",
    "This notebook automates the process of cleaning and transforming data for Wayfair product listings. The objective is to ensure the data meets required quality standards before analysis and reporting. \n",
    "\n",
    "Key tasks include:\n",
    "- Removing duplicates\n",
    "- Handling missing values\n",
    "- Normalizing product names\n",
    "- Ensuring consistent date formatsimport pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0afb7",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca21d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from ast import literal_eval\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.styles import PatternFill, Border, Side, Alignment, Font, numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ca1f5",
   "metadata": {},
   "source": [
    "# Define paths for files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78ee41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename = \"../data/raw/snap_m82yajn42myeb4szeo.json\"\n",
    "json_file_path = os.path.join(json_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e323d",
   "metadata": {},
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61bf8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46264fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sku_from_url(url: str):\n",
    "    try:\n",
    "        sku = url.split('?')[0].split('-')[-1].split('.')[0]\n",
    "        return sku\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting SKU from URL: {e}\")\n",
    "        return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb6574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/063yl0ms01z8skkqfmk94z9c0000gn/T/ipykernel_79703/2961258005.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: json.dumps(x) if isinstance(x, (list, dict)) else x)\n",
      "/var/folders/1p/063yl0ms01z8skkqfmk94z9c0000gn/T/ipykernel_79703/2961258005.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['regular_price'].fillna('{\"value\": 0, \"currency\": \"USD\", \"symbol\": \"$\"}', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Apply SKU extraction function\n",
    "df['wayfair_sku'] = df['url'].map(extract_sku_from_url)\n",
    "# Drop unnecessary columns and remove duplicates\n",
    "df.drop(['reviews'], axis=1, inplace=True)\n",
    "# Convert any columns with lists or dictionaries to strings for drop_duplicates to work\n",
    "df = df.applymap(lambda x: json.dumps(x) if isinstance(x, (list, dict)) else x)\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "# Rename columns for consistency\n",
    "df = df.rename(columns={'promo_price': 'discounted_retail_price', 'breadcrumbs': 'category'})\n",
    "df['regular_price'].fillna('{\"value\": 0, \"currency\": \"USD\", \"symbol\": \"$\"}', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047948d4",
   "metadata": {},
   "source": [
    "# Extracting product specifications and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db7ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle regular price column (parsing JSON safely)\n",
    "def safe_json_loads(x):\n",
    "    if pd.isna(x):  \n",
    "        return {\"value\": 0, \"currency\": \"USD\", \"symbol\": \"$\"}\n",
    "    try:\n",
    "        return json.loads(x)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c481b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply safe_json_loads to the 'specifications' column\n",
    "df['specifications_dict'] = df['specifications'].apply(safe_json_loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c96588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the safe json loading function\n",
    "df['regular_price_dict'] = df['regular_price'].apply(safe_json_loads)\n",
    "# Normalize the 'regular_price_dict' column and drop unused columns\n",
    "regular_price_df = pd.json_normalize(df['regular_price_dict'])\n",
    "df = pd.concat([df, regular_price_df], axis=1)\n",
    "df.drop(['regular_price', 'currency', 'symbol'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5689acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse 'specifications_details' from the 'specifications' column\n",
    "def extract_specifications_details(specifications):\n",
    "    if isinstance(specifications, dict):\n",
    "        return specifications.get('specifications_details', None)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27d54b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to extract 'specifications_details'\n",
    "df['specifications_details'] = df['specifications_dict'].apply(extract_specifications_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66138c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(s):\n",
    "    if not isinstance(s, str):  \n",
    "        return {}  \n",
    "    \n",
    "    # Extract the 'Features' section\n",
    "    features_str = re.search(r'Features:\\s*\\[(.*?)\\],', s)\n",
    "    \n",
    "    if features_str:\n",
    "        features_str = features_str.group(1)\n",
    "        \n",
    "        # Split into individual feature key-value pairs\n",
    "        features_list = features_str.split(', ')\n",
    "        \n",
    "        # Create a dictionary by splitting on the first ': ' for each pair\n",
    "        features_dict = {}\n",
    "        for feature in features_list:\n",
    "            key_value = feature.split(': ', 1)  \n",
    "            if len(key_value) == 2:\n",
    "                key, value = key_value\n",
    "                features_dict[key.strip()] = value.strip()  \n",
    "        \n",
    "        return features_dict\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73cda1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dollar_remover(record:str):\n",
    "    try:\n",
    "        price =  record.replace(\"$\",\"\")\n",
    "        return price\n",
    "    except:\n",
    "        return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f05d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the extract_features function\n",
    "df['parsed_features'] = df['specifications_details'].apply(extract_features)\n",
    "\n",
    "# Normalize parsed_features to combine\n",
    "df_features = pd.json_normalize(df['parsed_features'])\n",
    "\n",
    "# Concatenate the parsed features back to the original DataFrame\n",
    "df_combined = pd.concat([df, df_features], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b15a0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove $ sign\n",
    "df_combined['discounted_retail_price'] = df_combined['discounted_retail_price'].map(lambda x: dollar_remover(x),na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22dd1071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.rename(columns={'value':'regular_retail_price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08bf4726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df_combined.drop(['regular_price_dict', 'specifications_details', 'specifications_dict','parsed_features','specifications','input_url'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caf25f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential columns\n",
    "essential_columns = ['wayfair_sku', 'availability', 'average_ratings', 'category', 'combinations', 'description','regular_retail_price','discounted_retail_price']\n",
    "\n",
    "# The remaining columns by excluding the essential ones\n",
    "remaining_columns = [col for col in df_combined.columns if col not in essential_columns]\n",
    "\n",
    "# Combine essential columns with the remaining columns\n",
    "selected_columns = essential_columns + remaining_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1d9a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_combined[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723be786",
   "metadata": {},
   "source": [
    "# Excel file output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbebf9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../data/processed/wayfair_retail_data_20250313.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to an Excel file in the Downloads folder\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "output_filename = f\"../data/processed/wayfair_retail_data_{current_date}.xlsx\"\n",
    "output_path = os.path.join(output_filename)\n",
    "\n",
    "df_final.to_excel(output_path, index=False)\n",
    "print(f\"Data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d6ae4",
   "metadata": {},
   "source": [
    "# Excel Formatting and Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbb1f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad6a0e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Styled Excel file saved to: ../data/processed/wayfair_retail_data_20250313_styled.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Load the workbook and select the active worksheet\n",
    "wb = load_workbook(filename=file_path)\n",
    "ws = wb.active\n",
    "\n",
    "# Apply auto filter to the worksheet\n",
    "ws.auto_filter.ref = ws.dimensions\n",
    "\n",
    "# Define common styles\n",
    "font = Font(size=15, bold=True)\n",
    "wrap_alignment = Alignment(wrapText=True)\n",
    "left_alignment = Alignment(horizontal='left')\n",
    "fill = PatternFill(\"solid\", fgColor=\"00CCFFCC\")\n",
    "thin_border = Border(\n",
    "    top=Side(border_style='thin', color=\"FF000000\"),\n",
    "    bottom=Side(border_style='thin', color=\"FF000000\"),\n",
    "    left=Side(border_style='thin', color=\"FF000000\"),\n",
    "    right=Side(border_style='thin', color=\"FF000000\")\n",
    ")\n",
    "\n",
    "# Set row heights and apply left alignment to all rows\n",
    "last_row = ws.max_row\n",
    "for i in range(2, last_row + 1):\n",
    "    ws.row_dimensions[i].height = 15\n",
    "\n",
    "# Apply number format to specific columns\n",
    "for col in [\"B\", \"AJ\"]:\n",
    "    for cell in ws[col]:\n",
    "        cell.number_format = numbers.FORMAT_NUMBER\n",
    "\n",
    "# Apply alignment, border, and wrapping to all cells\n",
    "for row in ws.iter_rows(min_row=1, max_row=last_row):\n",
    "    for cell in row:\n",
    "        cell.alignment = left_alignment  \n",
    "        cell.border = thin_border        \n",
    "        cell.alignment = wrap_alignment  \n",
    "\n",
    "# Apply font and fill to header (first row)\n",
    "for cell in ws[\"1:1\"]:\n",
    "    cell.font = font\n",
    "    cell.fill = fill\n",
    "\n",
    "# Freeze the top row and first column\n",
    "ws.freeze_panes = ws[\"B2\"]\n",
    "\n",
    "# Set a standard column width for all columns\n",
    "for col in ws.columns:\n",
    "    ws.column_dimensions[col[0].column_letter].width = 30\n",
    "\n",
    "# Save the formatted workbook\n",
    "styled_file_path = os.path.join(f\"../data/processed/wayfair_retail_data_{current_date}_styled.xlsx\")\n",
    "wb.save(styled_file_path)\n",
    "\n",
    "print(f\"Styled Excel file saved to: {styled_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bdf05",
   "metadata": {},
   "source": [
    "#### Similar Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1fd9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_loads(item):\n",
    "    if pd.isna(item):  # Check if the item is NaN or None\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(item)  # Attempt to parse JSON\n",
    "    except json.JSONDecodeError:\n",
    "        return None  # Return None if JSON parsing fails\n",
    "\n",
    "# Ensure unique column names in the DataFrame\n",
    "df_final = df_final.loc[:, ~df_final.columns.duplicated()]\n",
    "\n",
    "# Apply the safe function to the 'similar_items' column\n",
    "df_final['parsed_similar_items'] = df_final['similar_items'].apply(safe_json_loads)\n",
    "\n",
    "# Expand the rows of the parsed_similar_items column\n",
    "expanded_rows = df_final.explode('parsed_similar_items')\n",
    "\n",
    "# Normalize the JSON data and retain the wayfair_sku column\n",
    "normalized_df = pd.json_normalize(expanded_rows['parsed_similar_items'])\n",
    "normalized_df['wayfair_sku'] = expanded_rows['wayfair_sku'].values\n",
    "normalized_df.to_excel('similar_items_wayfair.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
